{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine-Tune a Generative AI Model for Dialogue Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will fine-tune an existing LLM from Hugging Face for enhanced dialogue summarization. We will use the [OPT](https://huggingface.co/docs/transformers/model_doc/OPT) model, which provides a high quality instruction tuned model and can summarize text out of the box. To improve the inferences, you will explore a full fine-tuning approach and evaluate the results with ROUGE metrics. Then you will perform Parameter Efficient Fine-Tuning (PEFT), evaluate the resulting model and see that the benefits of PEFT outweigh the slightly-lower performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "TOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Convert the Ubuntu Dialogue Corpus into Q&A pairs\n",
    "\n",
    "Select the short Q&A discussions only from the Ubuntu Dialogue Corpus.\n",
    "\n",
    "**Acknowledgments**\n",
    "https://www.kaggle.com/datasets/rtatman/ubuntu-dialogue-corpus\n",
    "\n",
    "This dataset was ORIGINALLY collected by Ryan Lowe, Nissan Pow , Iulian V. Serban† and Joelle Pineau. It is made available here under the Apache License, 2.0. If you use this data in your work, please include the following citation:\n",
    "\n",
    "Ryan Lowe, Nissan Pow, Iulian V. Serban and Joelle Pineau, \"The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems\", SIGDial 2015. URL: http://www.sigdial.org/workshops/conference16/proceedings/pdf/SIGDIAL40.pdf\n",
    "\n",
    "**Parser** \n",
    "\n",
    "https://github.com/sedthh/Open-Assistant/blob/b3a8c2479b12ea69d66487e2852b836083b7e4db/data/datasets/ubuntu_dialogue_qa/ubuntu_parser.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LAION-AI/Open-Assistant/blob/data/datasets/ubuntu_dialogue/ubuntu_parser.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run below lines to set up if running in colab\n",
    "# !git clone https://github.com/LAION-AI/Open-Assistant.git\n",
    "# %cd Open-Assistant/data/datasets/ubuntu_dialogue/\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://dataset.cs.mcgill.ca/ubuntu-corpus-1.0/ubuntu_dialogs.tgz . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Module 7'  'Ubuntu Dialogue Corpus.zip'   toc.csv\n",
      " Research    Ubuntu-dialogue-corpus\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "\n",
    "FOLDER = \"../Ubuntu-dialogue-corpus\"  # input folder containing ubuntu dialogue csv files\n",
    "SOURCE = \"ubuntu-dialogue\"  # source to use in the parquet for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:19<00:00, 86.66s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>any ideas why java plugin takes so long to load?</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>java 1.4?</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>yes</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>java 1.5 loads _much_ faster</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-11-23 11:50:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>noneus: how can i get 1.5 is there a .deb some...</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date     from       to  \\\n",
       "0 2004-11-23 11:49:00+00:00  stuNNed      NaN   \n",
       "1 2004-11-23 11:49:00+00:00  crimsun  stuNNed   \n",
       "2 2004-11-23 11:49:00+00:00  stuNNed  crimsun   \n",
       "3 2004-11-23 11:49:00+00:00  crimsun  stuNNed   \n",
       "4 2004-11-23 11:50:00+00:00  stuNNed  crimsun   \n",
       "\n",
       "                                                text     id  \n",
       "0   any ideas why java plugin takes so long to load?  301_1  \n",
       "1                                          java 1.4?  301_1  \n",
       "2                                                yes  301_1  \n",
       "3                       java 1.5 loads _much_ faster  301_1  \n",
       "4  noneus: how can i get 1.5 is there a .deb some...  301_1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load(file):\n",
    "    data = pd.read_csv(file)\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data[\"id\"] = data[[\"folder\", \"dialogueID\"]].apply(lambda x: f\"{x[0]}_{x[1].split('.tsv')[0]}\" , axis=1)\n",
    "    data.drop(columns=[\"folder\", \"dialogueID\"], inplace=True)\n",
    "    return data\n",
    "\n",
    "data = None\n",
    "for file in tqdm(os.listdir(FOLDER)):\n",
    "    data = pd.concat([data, load(os.path.join(FOLDER, file))])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1852868/1852868 [04:01<00:00, 7657.74it/s] \n"
     ]
    }
   ],
   "source": [
    "# clean up the df, remove duplicates and answers that are way too short, etc.\n",
    "clean = {col:[] for col in [\"INSTRUCTION\", \"RESPONSE\", \"SOURCE\", \"METADATA\"]}\n",
    "\n",
    "for name, group in tqdm(data.groupby(\"id\")):\n",
    "    if len(group) < 3 or len(group) > 5:  # 3, 4, 5 len\n",
    "        continue  # back and forth will most likely not be parsed correctly\n",
    "    \n",
    "    group.sort_values(by=[\"date\"], ascending=True, inplace=True)\n",
    "    instruction = str(group[\"text\"].values[0]).strip()\n",
    "    insturction_user = group[\"from\"].values[0]\n",
    "    if not instruction or pd.isna(instruction) or len(instruction) < 12:\n",
    "        continue\n",
    "    if not re.findall(r'(?i)(?:\\?|what|who|where|why|when|how|whose|explain|tell|does|way|can|know|able|best|recommend)', instruction):\n",
    "        continue  # probably not a question\n",
    "    \n",
    "    all_recipients = \"|\".join([re.escape(item) for item in set(group[\"to\"].tolist() + group[\"from\"].tolist()) if pd.notna(item)])\n",
    "    response = None\n",
    "    response_user = None\n",
    "    for _, row in group.iterrows():\n",
    "        if row[\"to\"] == insturction_user:\n",
    "            candidate = str(row[\"text\"]).strip()\n",
    "            if not row[\"text\"] or pd.isna(row[\"text\"]) or re.findall(r'(?i)^(yes|yep|yeah|no|nah|nope|sure|yes\\s*sir)\\W*$', candidate):\n",
    "                continue  # answer is not expressive\n",
    "            if len(candidate) < 3:\n",
    "                continue  # too short\n",
    "            if re.findall(r'(?i)(?:wrong|of.*?topic|else\\s*where|ask.+?in|\\#\\w+|google|you.+?mean)', candidate):\n",
    "                continue  # probably off topic\n",
    "            if re.findall(r'\\b(' + all_recipients + r')\\b', candidate):\n",
    "                continue  # answer includes user name(s)\n",
    "            response = candidate\n",
    "            response_user = row[\"from\"]\n",
    "        elif response_user is not None and row[\"to\"] == response_user and row[\"from\"] == insturction_user:\n",
    "            if re.findall(r'(?i)(?:thank|thx|works|working|great)', str(row[\"text\"])):\n",
    "                clean[\"INSTRUCTION\"].append(instruction)\n",
    "                clean[\"RESPONSE\"].append(response)\n",
    "                clean[\"SOURCE\"].append(SOURCE)\n",
    "                clean[\"METADATA\"].append(json.dumps({\n",
    "                    \"user_question\": insturction_user,\n",
    "                    \"user_answer\": response_user\n",
    "                }))\n",
    "                break\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTRUCTION</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>METADATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, is there a CLI command to roll back any up...</td>\n",
       "      <td>your recourse is to re-install fresh the older...</td>\n",
       "      <td>ubuntu-dialogue</td>\n",
       "      <td>{\"user_question\": \"edd\", \"user_answer\": \"n8tus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A LiveCD iso can be burned to a DVD-R and run ...</td>\n",
       "      <td>I hope so, or the custom DVDs I've done are wo...</td>\n",
       "      <td>ubuntu-dialogue</td>\n",
       "      <td>{\"user_question\": \"usrl\", \"user_answer\": \"Ghos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello, is there a way to adjust gamma settings...</td>\n",
       "      <td>for me i have my nvidia settings manager and i...</td>\n",
       "      <td>ubuntu-dialogue</td>\n",
       "      <td>{\"user_question\": \"nucco_\", \"user_answer\": \"sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>does ubuntu come with a firewall by default?</td>\n",
       "      <td>no iptables rule is loaded by deault on ubuntu</td>\n",
       "      <td>ubuntu-dialogue</td>\n",
       "      <td>{\"user_question\": \"aeleon\", \"user_answer\": \"er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can someone tell me howto get rid of Google Ch...</td>\n",
       "      <td>sudo dpkg -l |grep -i chrom ----&gt; sudo apt-get...</td>\n",
       "      <td>ubuntu-dialogue</td>\n",
       "      <td>{\"user_question\": \"frold\", \"user_answer\": \"shi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         INSTRUCTION  \\\n",
       "0  hi, is there a CLI command to roll back any up...   \n",
       "1  A LiveCD iso can be burned to a DVD-R and run ...   \n",
       "2  hello, is there a way to adjust gamma settings...   \n",
       "4       does ubuntu come with a firewall by default?   \n",
       "5  Can someone tell me howto get rid of Google Ch...   \n",
       "\n",
       "                                            RESPONSE           SOURCE  \\\n",
       "0  your recourse is to re-install fresh the older...  ubuntu-dialogue   \n",
       "1  I hope so, or the custom DVDs I've done are wo...  ubuntu-dialogue   \n",
       "2  for me i have my nvidia settings manager and i...  ubuntu-dialogue   \n",
       "4     no iptables rule is loaded by deault on ubuntu  ubuntu-dialogue   \n",
       "5  sudo dpkg -l |grep -i chrom ----> sudo apt-get...  ubuntu-dialogue   \n",
       "\n",
       "                                            METADATA  \n",
       "0  {\"user_question\": \"edd\", \"user_answer\": \"n8tus...  \n",
       "1  {\"user_question\": \"usrl\", \"user_answer\": \"Ghos...  \n",
       "2  {\"user_question\": \"nucco_\", \"user_answer\": \"sp...  \n",
       "4  {\"user_question\": \"aeleon\", \"user_answer\": \"er...  \n",
       "5  {\"user_question\": \"frold\", \"user_answer\": \"shi...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = pd.DataFrame(clean)\n",
    "clean.sort_values(by=\"RESPONSE\", key=lambda x: x.str.len(), inplace=True, ascending=False)\n",
    "clean.drop_duplicates(subset=[\"INSTRUCTION\"], inplace=True)\n",
    "clean.sort_index(inplace=True)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0.87% of all questions (16181)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieved {len(clean) / len(data['id'].unique()) * 100.:.2f}% of all questions ({len(clean)})\")  # 19921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q > hi, is there a CLI command to roll back any updates/upgrades I made recently?\n",
      "A > your recourse is to re-install fresh the older version\n",
      "\n",
      "Q > A LiveCD iso can be burned to a DVD-R and run with no problems, right?\n",
      "A > I hope so, or the custom DVDs I've done are worthless. ;)\n",
      "\n",
      "Q > hello, is there a way to adjust gamma settings in totem? my videos aren't playing with the correct colours\n",
      "A > for me i have my nvidia settings manager and i change the video gamma settings from there...\n",
      "\n",
      "Q > does ubuntu come with a firewall by default?\n",
      "A > no iptables rule is loaded by deault on ubuntu\n",
      "\n",
      "Q > Can someone tell me howto get rid of Google Chrome? Im not able to uninstall it...\n",
      "A > sudo dpkg -l |grep -i chrom ----> sudo apt-get remove 'on what appears'\n",
      "\n",
      "Q > why is there competition between linux distros? They are all free...\n",
      "A > not really ontopic here but just personal preference\n",
      "\n",
      "Q > wow. for the life of me i can never remember this command. whats the command that outputs your ati hardare information? shows if you have direct rendering?\n",
      "A > glxinfo | grep dri ?\n",
      "\n",
      "Q > ack!  what the heck kind of Linux distro doesn't install traceroute by default?\n",
      "A > ubuntu\n",
      "\n",
      "Q > is there a way to see if a hard disk has bad blocks on ubuntu? fsck does the job?\n",
      "A > have you considered, however, monitoring your HD's state using the SMART sensors? (the 'smartmontools' package can be used to query them)\n",
      "\n",
      "Q > anyone know how to turn off opening things with a single click...its driving me crazy and I want to go back to doubleclicking\n",
      "A > open a file browser, go to edit|preferences | behavious, and change double to single\n",
      "\n",
      "Q > is there a graphical way to search for an nfs server on gutsy?\n",
      "A > does Places > Network work for you?\n",
      "\n",
      "Q > What's the best way for a bash script to pick up variables from /etc/environment? Should I just use source?\n",
      "A > if not, parse it\n",
      "\n",
      "Q > Hi, My Western Digital USB Passport Drive doesn't appear under ubuntu 7.10. Works fine in XP and from earlier versions of Ubuntu. Any ideas?\n",
      "A > I have one of those too.. it works nicely in ubuntu... needs a properly power-supplied usb port though\n",
      "\n",
      "Q > hi, I'm a bit low on disk space and I saw that /usr/src/linux-source* folder takes 2gb of space, so i was wondering whether is it safe to remove it?\n",
      "A > yes it safe to remove it\n",
      "\n",
      "Q > Where can I find a detailed description of scrollkeeper?\n",
      "A > http://scrollkeeper.sourceforge.net/documentation.shtml ?\n",
      "\n",
      "Q > whats the human readable command for hardware info?\n",
      "A > I'm sure you can guess ls hw :)\n",
      "\n",
      "Q > How do I move a file from one place to another in console?\n",
      "A > use mv\n",
      "\n",
      "Q > is there any reason why I should not use proposed packages ?? I just enabled proposed because I need ff3rc1\n",
      "A > you could download the package from packages.ubuntu.com and install it without enabling the proposed repo.\n",
      "\n",
      "Q > Where can I find full DVD of hardy for amd64 ???\n",
      "A > http://www.acc.umu.se/~mighty/ubuntu/ubuntu-8.04-dvd-amd64.iso.torrent\n",
      "\n",
      "Q > where can i find a log of the latest updates ubuntu has done?\n",
      "A > /var/log/dpkg\n",
      "\n",
      "Q > hi folks. i am trying to convert screencast I made to mpeg4     but when I try    ffmpeg -i ~/out.mpg -ar 22050 blah.mp4          I get Unsupported codec for output     .   Any clue which package I need for this?\n",
      "A > you probably the ffmpeg binaries from medibuntu to get mp4 support due to patent issues\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in clean.iterrows():\n",
    "    print(\"Q >\", row[\"INSTRUCTION\"])\n",
    "    print(\"A >\", row[\"RESPONSE\"])\n",
    "    print()\n",
    "    if index > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.to_csv('clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "### 1.1 - Set up Kernel and Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75aa9b897ef64d9f85770d0d90ff2763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --disable-pip-version-check \\\n",
    "#     torch==1.13.1 \\\n",
    "#     torchdata==0.5.1 --quiet\n",
    "\n",
    "# !pip install \\\n",
    "#     transformers==4.27.2 \\\n",
    "#     datasets==2.11.0 \\\n",
    "#     evaluate==0.4.0 \\\n",
    "#     rouge_score==0.1.2 \\\n",
    "#     loralib==0.1.1 \\\n",
    "#     peft==0.3.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer, AutoModelForCausalLM\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, AutoModelForSeq2SeqLM\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 - Load Dataset and LLM\n",
    "\n",
    "You are going to continue experimenting with the [ubuntu_dialogs_corpus](https://huggingface.co/datasets/ubuntu_dialogs_corpus) Hugging Face dataset. \n",
    "\n",
    "Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words. This provides a unique resource for research into building dialogue managers based on neural language models that can make use of large amounts of unlabeled data. The dataset has both the multi-turn property of conversations in the Dialog State Tracking Challenge datasets, and the unstructured nature of interactions from microblog services such as Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using v2 of the ubuntu_dialogs_corpus\n",
    "\n",
    "preprocesed during download for steming and lammetization   \n",
    "Source https://github.com/rkadlec/ubuntu-ranking-dataset-creator  \n",
    "!git clone https://github.com/rkadlec/ubuntu-ranking-dataset-creator.git .  \n",
    "./ubuntu-ranking-dataset-creator/src/./generate.sh   \n",
    "!cp ./ubuntu-ranking-dataset-creator/src/*.csv  ../Datasets/Ubuntu-corpus  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/jupyter/.cache/huggingface/datasets/csv/default-2e0c7a9fed0024c6/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8459633b7f2d4f0aad6594168fb2e84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"csv\", data_files = \"./clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['INSTRUCTION', 'RESPONSE', 'SOURCE', 'METADATA'],\n",
       "        num_rows: 16181\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename features\n",
    "data['train'] = data['train'].rename_column('INSTRUCTION', 'context') \n",
    "data['train'] = data['train'].rename_column('RESPONSE', 'response')\n",
    "\n",
    "# Drop features\n",
    "data['train'] = data['train'].remove_columns(['SOURCE', 'METADATA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corpus = pd.DataFrame(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, is there a CLI command to roll back any up...</td>\n",
       "      <td>your recourse is to re-install fresh the older...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A LiveCD iso can be burned to a DVD-R and run ...</td>\n",
       "      <td>I hope so, or the custom DVDs I've done are wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello, is there a way to adjust gamma settings...</td>\n",
       "      <td>for me i have my nvidia settings manager and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>does ubuntu come with a firewall by default?</td>\n",
       "      <td>no iptables rule is loaded by deault on ubuntu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can someone tell me howto get rid of Google Ch...</td>\n",
       "      <td>sudo dpkg -l |grep -i chrom ----&gt; sudo apt-get...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  hi, is there a CLI command to roll back any up...   \n",
       "1  A LiveCD iso can be burned to a DVD-R and run ...   \n",
       "2  hello, is there a way to adjust gamma settings...   \n",
       "3       does ubuntu come with a firewall by default?   \n",
       "4  Can someone tell me howto get rid of Google Ch...   \n",
       "\n",
       "                                            response  \n",
       "0  your recourse is to re-install fresh the older...  \n",
       "1  I hope so, or the custom DVDs I've done are wo...  \n",
       "2  for me i have my nvidia settings manager and i...  \n",
       "3     no iptables rule is loaded by deault on ubuntu  \n",
       "4  sudo dpkg -l |grep -i chrom ----> sudo apt-get...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample questions with responses in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_questions=[\n",
    "    \"does ubuntu come with a firewall by default?\",\n",
    "    \"Can grub-install work with ext3?\",\n",
    "    \"Is there a CLI command to roll back updates?\",\n",
    "    \"How do I get rid of rid of Google Chrome?\"\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentation: Goal is to create a support bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2dae4a028a482ea7c770fde1e64cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name='facebook/opt-6.7b'\n",
    "\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                                       device_map=\"auto\",\n",
    "                                                       load_in_8bit=True,\n",
    "                                                       torch_dtype=torch.float16 )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model with Zero Shot Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_zero_shot(question, model_eval):\n",
    "    test_inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "\n",
    "    ## Asign Inputs to GPU|\n",
    "    with torch.cuda.amp.autocast():\n",
    "        test_inputs = test_inputs.to('cuda')\n",
    "        test_outputs = model_eval.generate(**test_inputs,\n",
    "                            max_new_tokens=64,\n",
    "                            repetition_penalty=2.1,\n",
    "                            length_penalty = 1.8,\n",
    "                            temperature = 1)\n",
    "                           \n",
    "    return tokenizer.decode(test_outputs[0], skip_special_tokens=True, padding_side='left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: does ubuntu come with a firewall by default? \n",
      "\n",
      "Model Output: does ubuntu come with a firewall by default?\n",
      "Yes, it comes pre-installed.  I'm not sure if you can disable the built in one though...I've never tried to do that before but maybe someone else knows for certain! :)\n",
      "\n",
      " Edit: Just checked and yes - there is an option under System > Administration (or something like this) called \n",
      "\n",
      "Question: Can grub-install work with ext3? \n",
      "\n",
      "Model Output: Can grub-install work with ext3?\n",
      "I don't think so.  I've never tried it, but the documentation says that you need to use EXT4 for GRUB2 and XFS or BTRfs (or something like this) if using a filesystem other than FAT32/NTFS on Linux systems... which is what Grubby uses \n",
      "\n",
      "Question: Is there a CLI command to roll back updates? \n",
      "\n",
      "Model Output: Is there a CLI command to roll back updates?\n",
      "I don't think so.  I've never seen one, but it would be nice if you could do that! :)\n",
      "\n",
      " You can always just uninstall the update and then reinstall from scratch though...that's what we did when this happened on our server last week (it was an upgrade). It took about \n",
      "\n",
      "Question: How do I get rid of rid of Google Chrome? \n",
      "\n",
      "Model Output: How do I get rid of rid of Google Chrome?\n",
      "You can't. It's a part os the OS, and you have to use it for some things (like using google maps).  You could try uninstalling chrome from your computer though... but that would be like trying not having internet access on an iPhone or something :P. If there is no other \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in sample_questions:\n",
    "    print(\"Question:\",question,\"\\n\")\n",
    "    print(\"Model Output:\",test_model_with_zero_shot(question, original_model),\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in original_model.parameters():\n",
    "  param.requires_grad = False  # freeze the model - train adapters later\n",
    "  if param.ndim == 1:\n",
    "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "original_model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "original_model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "original_model.lm_head = CastOutputToFloat(original_model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_len = 762\n",
    "\n",
    "def tokenize_function(example):\n",
    "    #start_prompt = 'Act like a chat agent in a turn conversation similar to this dialogue between two individuals where one individual is looking to resolve Ubuntu technical issues. For every new request, provide a response\\n\\n'\n",
    "    start_prompt = \"\"\"\n",
    "    Technical Question: \\n\n",
    "    \"\"\"\n",
    "    end_prompt = '\\n\\nCorrect response to technical question: \\n '\n",
    "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"context\"]]\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", max_length=max_seq_len, truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"response\"],padding=\"max_length\", max_length=max_seq_len, truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "tokenized_datasets = data.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['response', 'context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (16181, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 16181\n",
      "    })\n",
      "})\n",
      "{'input_ids': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 50118, 1437, 1437, 1437, 12920, 15680, 35, 1437, 50140, 1437, 1437, 1437, 20280, 6, 16, 89, 10, 45919, 5936, 7, 3825, 124, 143, 3496, 73, 658, 25579, 38, 156, 682, 116, 50118, 50118, 33567, 1263, 7, 3165, 864, 35, 1437, 50118, 1437]], 'labels': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 16625, 32688, 16, 7, 769, 12, 39567, 2310, 5, 2530, 1732]]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "\n",
    "\n",
    "print(tokenized_datasets)\n",
    "print(tokenized_datasets['train'][:1])\n",
    "# print(tokenized_datasets['train'][:1]['input_ids'][0])\n",
    "# print(tokenized_datasets['train'][:1]['labels'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Setup the PEFT/LoRA model for Fine-Tuning\n",
    "\n",
    "You need to set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "\n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    " r=32,\n",
    " lora_alpha=32,\n",
    " target_modules=[\"q_proj\", \"v_proj\"],\n",
    " lora_dropout=0.01,\n",
    " bias=\"none\",\n",
    " task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare int-8 model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_int8 = prepare_model_for_int8_training(original_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add LoRA adaptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16777216 || all params: 6675251200 || trainable%: 0.2513346014603915\n"
     ]
    }
   ],
   "source": [
    "model_int8_lora = get_peft_model(original_model, lora_config)\n",
    "model_int8_lora.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Train PEFT Adapter\n",
    "\n",
    "Define training arguments and create `Trainer` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    max_steps=100,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=20, \n",
    "    fp16=True,\n",
    "    save_strategy = \"no\"\n",
    ")\n",
    "    \n",
    "trainer = Trainer(\n",
    "    model=model_int8_lora,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "original_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 10:36, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.538800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.833500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.674500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=3.2024721908569336, metrics={'train_runtime': 642.7601, 'train_samples_per_second': 1.245, 'train_steps_per_second': 0.156, 'total_flos': 2.36315351973888e+16, 'train_loss': 3.2024721908569336, 'epoch': 0.05})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('results-opt/tokenizer_config.json',\n",
       " 'results-opt/special_tokens_map.json',\n",
       " 'results-opt/vocab.json',\n",
       " 'results-opt/merges.txt',\n",
       " 'results-opt/added_tokens.json',\n",
       " 'results-opt/tokenizer.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save our LoRA model & tokenizer results\n",
    "peft_model_id=\"results-opt\"\n",
    "trainer.model.save_pretrained(peft_model_id)\n",
    "tokenizer.save_pretrained(peft_model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate & run Inference with LoRA OPT\n",
    "\n",
    "We are going to use evaluate library to evaluate the rogue score. We can run inference using PEFT and transformers. For our OPT large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7c31bb05a7488cbd22e76035883066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "# Load peft config for pre-trained checkpoint etc. \n",
    "\n",
    "peft_model_id = \"results-opt\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "\n",
    "## Load the Lora model\n",
    "test_model = PeftModel.from_pretrained(base_model, peft_model_id, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): OPTForCausalLM(\n",
       "      (model): OPTModel(\n",
       "        (decoder): OPTDecoder(\n",
       "          (embed_tokens): Embedding(50272, 4096, padding_idx=1)\n",
       "          (embed_positions): OPTLearnedPositionalEmbedding(2050, 4096)\n",
       "          (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (layers): ModuleList(\n",
       "            (0): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (4): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (5): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (6): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (7): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (8): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (9): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (10): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (11): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (12): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (13): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (14): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (15): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (16): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (17): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (18): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (19): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (20): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (21): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (22): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (23): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (24): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (25): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (26): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (27): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (28): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (29): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (30): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (31): OPTDecoderLayer(\n",
       "              (self_attn): OPTAttention(\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=True\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc2): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (final_layer_norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=50272, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with sample questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: does ubuntu come with a firewall by default? \n",
      "\n",
      "Model Output: does ubuntu come with a firewall by default?\n",
      "Yes, it does.  I'm not sure what you're trying to do here... but if your goal is \"to get rid of the built-in firewalls\", then no - Ubuntu doesn't have one either (unless there's some other reason for this post).. and even so that would be \n",
      "\n",
      "Question: Can grub-install work with ext3? \n",
      "\n",
      "Model Output: Can grub-install work with ext3?\n",
      "I don't think so.  I'm pretty sure it's a 4 partition thing, and the installer is only for 2 partitions (ext2/4) or 3).\n",
      "\n",
      " If you want to try installing ubuntu on an external hard drive then booting from that way...it works fine! :) good luck \n",
      "\n",
      "Question: Is there a CLI command to roll back updates? \n",
      "\n",
      "Model Output: Is there a CLI command to roll back updates?\n",
      "sudo apt-get distupgrade -y  This will downgrade your system. You can then upgrade again after you're done with this, but it's not recommended as the process is very easy and quick if that fails for whatever reason (I've had issues in past where I needed an update). It should be \n",
      "\n",
      "Question: How do I get rid of rid of Google Chrome? \n",
      "\n",
      "Model Output: How do I get rid of rid of Google Chrome?\n",
      "I'm not sure if you can uninstall it, but there are a few ways to disable the extension.  1) Right click on chrome and select 'extensions' 2)... Disable all extensions 3). Restart browser 4.) Enable one at time 5.). Repeat steps until desired effect is achieved :) Hope this helps \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in sample_questions:\n",
    "    print(\"Question:\",question,\"\\n\")\n",
    "    print(\"Model Output:\",test_model_with_zero_shot(question, test_model),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@tom_21755/understanding-causal-llms-masked-llm-s-and-seq2seq-a-guide-to-language-model-training-d4457bbd07fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: how do you mount a cd \n",
      "\n",
      "Model Output: how do you mount a cd drive to the back of your case?\n",
      "I used velcro and zip ties. I also have it mounted on my desk with an external power supply so that i can just plug in when needed, but its not necessary for this build as there is no need at all since im using sata drives only :)  Edit \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(serving(\"how do you mount a cd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://22f7c53c8d95bf6216.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://22f7c53c8d95bf6216.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def serving(sample):\n",
    "    return test_model_with_zero_shot(sample,test_model)\n",
    "\n",
    "demo = gr.Interface(fn=serving, inputs=\"text\", outputs=\"text\")\n",
    "    \n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "name": "Fine-tune a language model",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
