{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# [Dataset](#Methodology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this section we will discuss the clean up of the Ubuntu Dialog Corpus and create Q&A Pairs that we will use to train the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The Ubuntu Dialogue Corpus consists of approximately one million two-person dialogues derived from Ubuntu tech support chat logs. These natural language interactions average 8 turns per conversation and collectively contain over 100 million words. The dataset includes an identifier for each dialogue along with timestamps, sender and recipient information, and the text content of each turn in the conversation - all formatted as text rather than audio. A sample subset of this corpus is available in .csv format across multiple files. Collected by researchers Ryan Lowe et al., this corpus is licensed under Apache License 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetInfo\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we processes and combine data from multiple CSV files in the Ubuntu dialogue corpus. Each file is loaded, date is converted to a standardized format, a unique ID is generated by combining folder and dialogueID columns, and original columns are dropped. Finally, all processed data from different files are combined into one large dataframe for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [05:42<00:00, 114.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Global settings\n",
    "FOLDER = \"./Ubuntu-dialogue-corpus\"  # Input folder containing Ubuntu dialogue CSV files\n",
    "SOURCE = \"ubuntu-dialogue\"  # Source to use in the parquet for each row\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\"Loads a CSV file and processes its content.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Load CSV file into a DataFrame\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert 'date' column to datetime format\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    \n",
    "    # Generate 'id' column by combining 'folder' and 'dialogueID' columns, \n",
    "    # and removing '.tsv' extension from 'dialogueID' values\n",
    "    data[\"id\"] = data.apply(lambda row: f\"{row['folder']}_{row['dialogueID'].split('.tsv')[0]}\", axis=1)\n",
    "    \n",
    "    # Drop the original 'folder' and 'dialogueID' columns\n",
    "    data.drop(columns=[\"folder\", \"dialogueID\"], inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def aggregate_data(folder_path):\n",
    "    \"\"\"Aggregates data from all CSV files in the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing the CSV files.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Aggregated DataFrame.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame for data aggregation\n",
    "    aggregated_data = pd.DataFrame()\n",
    "    \n",
    "    # Iterate through each file in the specified folder\n",
    "    for file_name in tqdm(os.listdir(folder_path)):\n",
    "        # Construct the full path to the current file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Load and process the current file\n",
    "        current_data = load_csv(file_path)\n",
    "        \n",
    "        # Concatenate the current data with the aggregated data\n",
    "        aggregated_data = pd.concat([aggregated_data, current_data])\n",
    "    \n",
    "    return aggregated_data\n",
    "\n",
    "# Call the aggregate_data function to process and aggregate all CSV files in the specified folder\n",
    "aggregated_data = aggregate_data(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>any ideas why java plugin takes so long to load?</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>java 1.4?</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>yes</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-11-23 11:49:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>java 1.5 loads _much_ faster</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-11-23 11:50:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>noneus: how can i get 1.5 is there a .deb some...</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2004-11-23 11:50:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>not yet.</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2004-11-23 11:50:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>noneus: is this blackdown or sun?</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2004-11-23 11:50:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>did you install just the jre?</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2004-11-23 11:51:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>I use IBM's 1.4.2</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2004-11-23 11:51:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>(jdk, because I do globus development)</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2004-11-23 11:52:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>ah ok then, i'll give it a try, does IBM have ...</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2004-11-23 11:52:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>yes</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2004-11-23 11:52:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>thanks, i'll try that, screwed up and tried to...</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004-11-23 11:57:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>can't seem to find an ibm jre package, would y...</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2004-11-23 11:59:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>https://www6.software.ibm.com/dl/lxdk/lxdk-p</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2004-11-23 11:59:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>you have to create a login.</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2004-11-23 11:59:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>much appreciated</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2004-11-23 12:09:00+00:00</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>1.42 is latest IBM java?</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2004-11-23 12:10:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>yes.</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2004-11-23 12:10:00+00:00</td>\n",
       "      <td>crimsun</td>\n",
       "      <td>stuNNed</td>\n",
       "      <td>for certain arches</td>\n",
       "      <td>301_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date     from       to  \\\n",
       "0  2004-11-23 11:49:00+00:00  stuNNed      NaN   \n",
       "1  2004-11-23 11:49:00+00:00  crimsun  stuNNed   \n",
       "2  2004-11-23 11:49:00+00:00  stuNNed  crimsun   \n",
       "3  2004-11-23 11:49:00+00:00  crimsun  stuNNed   \n",
       "4  2004-11-23 11:50:00+00:00  stuNNed  crimsun   \n",
       "5  2004-11-23 11:50:00+00:00  crimsun  stuNNed   \n",
       "6  2004-11-23 11:50:00+00:00  stuNNed  crimsun   \n",
       "7  2004-11-23 11:50:00+00:00  stuNNed  crimsun   \n",
       "8  2004-11-23 11:51:00+00:00  crimsun  stuNNed   \n",
       "9  2004-11-23 11:51:00+00:00  crimsun  stuNNed   \n",
       "10 2004-11-23 11:52:00+00:00  stuNNed  crimsun   \n",
       "11 2004-11-23 11:52:00+00:00  crimsun  stuNNed   \n",
       "12 2004-11-23 11:52:00+00:00  stuNNed  crimsun   \n",
       "13 2004-11-23 11:57:00+00:00  stuNNed  crimsun   \n",
       "14 2004-11-23 11:59:00+00:00  crimsun  stuNNed   \n",
       "15 2004-11-23 11:59:00+00:00  crimsun  stuNNed   \n",
       "16 2004-11-23 11:59:00+00:00  stuNNed  crimsun   \n",
       "17 2004-11-23 12:09:00+00:00  stuNNed  crimsun   \n",
       "18 2004-11-23 12:10:00+00:00  crimsun  stuNNed   \n",
       "19 2004-11-23 12:10:00+00:00  crimsun  stuNNed   \n",
       "\n",
       "                                                 text     id  \n",
       "0    any ideas why java plugin takes so long to load?  301_1  \n",
       "1                                           java 1.4?  301_1  \n",
       "2                                                 yes  301_1  \n",
       "3                        java 1.5 loads _much_ faster  301_1  \n",
       "4   noneus: how can i get 1.5 is there a .deb some...  301_1  \n",
       "5                                            not yet.  301_1  \n",
       "6                   noneus: is this blackdown or sun?  301_1  \n",
       "7                       did you install just the jre?  301_1  \n",
       "8                                   I use IBM's 1.4.2  301_1  \n",
       "9              (jdk, because I do globus development)  301_1  \n",
       "10  ah ok then, i'll give it a try, does IBM have ...  301_1  \n",
       "11                                                yes  301_1  \n",
       "12  thanks, i'll try that, screwed up and tried to...  301_1  \n",
       "13  can't seem to find an ibm jre package, would y...  301_1  \n",
       "14       https://www6.software.ibm.com/dl/lxdk/lxdk-p  301_1  \n",
       "15                        you have to create a login.  301_1  \n",
       "16                                   much appreciated  301_1  \n",
       "17                           1.42 is latest IBM java?  301_1  \n",
       "18                                               yes.  301_1  \n",
       "19                                 for certain arches  301_1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first five rows of the aggregated data to verify the results\n",
    "aggregated_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation**\n",
    "- The oringal dataset comprising of 100M examples is loaded into a  dataframe that has the `date`, `from`, to `and` text `and` `id` columns.  One can track the conversation in this dataset through looking at  `id` and `to` and `from`. \n",
    "- On first glance, it is difficult to intutively follow the conversations in this this `chatroom`. We will further process this data to create nice question and answer pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Question and Answer Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we processess the  `aggregated_data` dataframe of conversations, refining it into a more understandable format. The `is_valid_question` function checks if a question meets specific criteria, like having at least 12 characters and containing common question words (e.g., 'what', 'who'). The `is_expressive_answer` function examines if an answer is descriptive and relevant, filtering out short or off-topic responses. It also removes responses containing certain words (e.g., 'google' or 'wrong') and those that are simple affirmatives or negatives (e.g., 'yes', 'no'). The `clean_dataframe` function then uses these two functions to process the entire chat data, removing any unneeded conversations and organizing the remaining valid questions and their corresponding expressive answers into a cleaner format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:57<00:00, 19.12s/it]\n",
      "100%|██████████| 1852868/1852868 [03:57<00:00, 7815.52it/s] \n"
     ]
    }
   ],
   "source": [
    "SOURCE = \"ubuntu-dialogue\"\n",
    "\n",
    "def is_valid_question(question):\n",
    "    \"\"\"Checks if the question is valid based on certain criteria.\"\"\"\n",
    "    if not question or pd.isna(question) or len(question) < 12:\n",
    "        return False\n",
    "    question_keywords = re.findall(r'(?i)(?:\\?|what|who|where|why|when|how|whose|explain|tell|does|way|can|know|able|best|recommend)', question)\n",
    "    return bool(question_keywords)\n",
    "\n",
    "def is_expressive_answer(candidate, all_recipients):\n",
    "    \"\"\"Checks if the answer is expressive and on-topic based on certain criteria.\"\"\"\n",
    "    if not candidate or pd.isna(candidate) or re.findall(r'(?i)^(yes|yep|yeah|no|nah|nope|sure|yes\\s*sir)\\W*$', candidate):\n",
    "        return False\n",
    "    if len(candidate) < 3 or re.findall(r'(?i)(?:wrong|of.*?topic|else\\s*where|ask.+?in|\\#\\w+|google|you.+?mean)', candidate):\n",
    "        return False\n",
    "    if re.findall(r'\\b(' + all_recipients + r')\\b', candidate):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def clean_dataframe(data):\n",
    "    \"\"\"Cleans up the DataFrame, removes duplicates, and processes conversations.\"\"\"\n",
    "    clean_dict = {col: [] for col in [\"question\", \"answer\"]}\n",
    "\n",
    "    for name, group in tqdm(data.groupby(\"id\")):\n",
    "        if len(group) not in (3, 4, 5):  # Checking for valid conversation length\n",
    "            continue\n",
    "\n",
    "        group.sort_values(by=[\"date\"], ascending=True, inplace=True)\n",
    "        question = str(group[\"text\"].values[0]).strip()\n",
    "        question_user = group[\"from\"].values[0]\n",
    "\n",
    "        if not is_valid_question(question):\n",
    "            continue\n",
    "\n",
    "        all_recipients = \"|\".join([re.escape(item) for item in set(group[\"to\"].tolist() + group[\"from\"].tolist()) if pd.notna(item)])\n",
    "        answer = None\n",
    "        answer_user = None\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            if row[\"to\"] == question_user:\n",
    "                candidate = str(row[\"text\"]).strip()\n",
    "                if is_expressive_answer(candidate, all_recipients):\n",
    "                    answer = candidate\n",
    "                    answer_user = row[\"from\"]\n",
    "            elif answer_user is not None and row[\"to\"] == answer_user and row[\"from\"] == question_user:\n",
    "                if re.findall(r'(?i)(?:thank|thanks|perfect|thx|works|working|great|good|awesome)', str(row[\"text\"])):\n",
    "                    clean_dict[\"question\"].append(question)\n",
    "                    clean_dict[\"answer\"].append(answer)\n",
    "                    break\n",
    "\n",
    "    return clean_dict\n",
    "\n",
    "# Usage:\n",
    "FOLDER = \"./Ubuntu-dialogue-corpus\"  # Input folder containing Ubuntu dialogue CSV files\n",
    "data = None\n",
    "for file in tqdm(os.listdir(FOLDER)):\n",
    "    data = pd.concat([data, pd.read_csv(os.path.join(FOLDER, file))])\n",
    "\n",
    "clean_data = clean_dataframe(aggregated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.DataFrame(clean_data)\n",
    "clean.sort_values(by=\"answer\", key=lambda x: x.str.len(), inplace=True, ascending=False)\n",
    "clean.drop_duplicates(subset=[\"question\"], inplace=True)\n",
    "clean.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0.93% of all questions (17178)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieved {len(clean) / len(aggregated_data['id'].unique()) * 100.:.2f}% of all questions ({len(clean)})\")  # 19921"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation**\n",
    "- We have cut down the number of examples from 100M to slightly over 10000 question and answer pairs. We will be using the LoRA technique and the reduced number of examples is going to be sufficient to train an model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert text to lowercase and and remove spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, is there a cli command to roll back any up...</td>\n",
       "      <td>your recourse is to re-install fresh the older...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a livecd iso can be burned to a dvd-r and run ...</td>\n",
       "      <td>i hope so, or the custom dvds i've done are wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello, is there a way to adjust gamma settings...</td>\n",
       "      <td>for me i have my nvidia settings manager and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>does ubuntu come with a firewall by default?</td>\n",
       "      <td>no iptables rule is loaded by deault on ubuntu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>can someone tell me howto get rid of google ch...</td>\n",
       "      <td>sudo dpkg -l |grep -i chrom ----&gt; sudo apt-get...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  hi, is there a cli command to roll back any up...   \n",
       "1  a livecd iso can be burned to a dvd-r and run ...   \n",
       "2  hello, is there a way to adjust gamma settings...   \n",
       "4       does ubuntu come with a firewall by default?   \n",
       "5  can someone tell me howto get rid of google ch...   \n",
       "\n",
       "                                              answer  \n",
       "0  your recourse is to re-install fresh the older...  \n",
       "1  i hope so, or the custom dvds i've done are wo...  \n",
       "2  for me i have my nvidia settings manager and i...  \n",
       "4     no iptables rule is loaded by deault on ubuntu  \n",
       "5  sudo dpkg -l |grep -i chrom ----> sudo apt-get...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To convert all text in `question` and `answer` into lowercase\n",
    "clean['question'] = clean['question'].str.lower()\n",
    "clean['answer'] = clean['answer'].str.lower()\n",
    "\n",
    "# To remove more than one space from 'question' and 'answer'\n",
    "clean['question'] = clean['question'].str.replace(r'\\s{2,}', ' ', regex=True)\n",
    "clean['answer'] = clean['answer'].str.replace(r'\\s{2,}', ' ', regex=True)\n",
    "\n",
    "# Now display the first few rows of the cleaned dataframe\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 12024\n",
      "Testing set size: 5154\n"
     ]
    }
   ],
   "source": [
    "clean = clean.sample(frac = 1)\n",
    "\n",
    "# Split the data\n",
    "train, test = train_test_split(clean, test_size=0.30)\n",
    "\n",
    "print(\"Training set size:\", len(train))\n",
    "print(\"Testing set size:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation**\n",
    "- After cleaning the dataset, we were left with 0.93% of all questions, totaling 17,178. We divided these into training and testing data using a 70/30 split. The training set consists of 12,100 questions, while the testing set comprises 5,186 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q > i am trying to share folders with nfs through a wireless router, but the shared folder does not show up in the network. would someone help me with this?\n",
      "A > using nfs over wifi is a bad idea because the protocol does not gracefully handle disconnection. i suggest smb of sshfs instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in clean.iterrows():\n",
    "    print(\"Q >\", row[\"question\"])\n",
    "    print(\"A >\", row[\"answer\"])\n",
    "    print()\n",
    "    if index > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation**\n",
    "- We ended up with a clean set of question and answer pairs. Since the downstream task is answer technical questions with special characters, we are limited on how much we can process the data like removing punctcations, ascii characters etc and so leave them in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create .jsonl file  and upload the cleaned up dataset to huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the dataset into JSONL also called newline-delimited JSON. JSON Lines is a convenient format for storing structured data that may be processed one record at a time and take the following structure\n",
    "\n",
    "```\n",
    "{\"question\": \"What color is the sky?\", \"answer\": \"The sky is blue.\"}\n",
    "{\"question\": \"Where is the best place to get cloud GPUs?\", \"answer\": \"Lambda.com\"}\n",
    "{\"question\": \"Why do Americans love guns so much?\", \"output\": \"answer of the Spanish.\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into huggingface \n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl(dataframe, filename):\n",
    "    with open(filename+'.jsonl', 'w') as f:\n",
    "      for i, row in dataframe.iterrows():\n",
    "        record = {\n",
    "          'question': row['question'].strip(),\n",
    "          'answer': row['answer'].strip(),\n",
    "        }\n",
    "        json_record = json.dumps(record)\n",
    "        f.write(json_record+'\\n')\n",
    "    \n",
    "create_jsonl(test,\"test\")\n",
    "create_jsonl(train,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/jupyter/.cache/huggingface/datasets/json/default-66aeeca9882648bc/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36f76fc569d40cfb6707d83778cb1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b8abe822c94297a6bfeb79700f6970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/jupyter/.cache/huggingface/datasets/json/default-66aeeca9882648bc/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e900182a7242aab0593989d0114e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ubuntu_question_answer_jsonl = load_dataset(\"json\", data_files = {\"train\": \"./train.jsonl\",\"test\": \"./test.jsonl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 12024\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 5154\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubuntu_question_answer_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf9a6bc882f442fb256f20d449359fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d32c4815ac9429ab00ea6665a8088c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ef2d4e9c8e4628997505d41f3057d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c688ba52409f45edb9e8cde65df359f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58c01b3b2b43c28d4d9867c9c8e0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c213b48ad3460d9e4bf5f2e4747558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ubuntu_question_answer_jsonl.push_to_hub(\"mugithi/ubuntu_question_answer\", private=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**observation**\n",
    "- We uploaded the data into hugginface so that we can easily download the the preprocessed data from the hugginface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook,we ingested the initial dataset encompassing 100 million examples was ingested into a dataframe, with designated columns for date, from, to, text, and id, facilitating the tracing of dialogues within the dataset via the id, to, and from fields. Upon initial examination, navigating through the conversations in this 'chatroom' proved to be non-intuitive. Subsequent steps were taken to refine this data into well-structured question and answer pairs for ease of analysis. Post-cleaning, a mere 0.93% of the original questions remained, summing up to 17,178 entries. This refined dataset was then partitioned into training and testing subsets following a 70/30 ratio, yielding 12,100 questions for training and 5,186 for testing purposes. Further enhancing the accessibility and usability of the preprocessed data, it was uploaded to Hugging Face, thereby simplifying the retrieval process for future endeavors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowe, R., Pow, N., Serban, I., & Pineau, J. (2016). The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems. Retrieved from https://doi.org/10.48550/arXiv.1506.08909\n",
    "\n",
    "Nagyfi, R. (2023). Open-Assistant/ubuntu_parser.ipynb. Retrieved from https://github.com/sedthh/Open-Assistant/blob/b3a8c2479b12ea69d66487e2852b836083b7e4db/data/datasets/ubuntu_dialogue_qa/ubuntu_parser.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "name": "Fine-tune a language model",
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
